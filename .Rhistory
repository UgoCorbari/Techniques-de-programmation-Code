return(all_matches)
}
# Liste des URLs
url_matches <- c(
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402015",
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016"
)
# Appel de la fonction
results <- process_matches(url_matches, save_path = "match_results.rds")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matches <- c(
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402018",
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016"
)
# Appel de la fonction
results <- process_matches(url_matches, save_path = "match_results.rds")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
---
title: "Techniques de programmation"
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matche <- c("https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016")
# Appel de la fonction
results <- process_matches(url_matche, save_path = "match_results.rds")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matche <- c("https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016")
# Appel de la fonction
results <- process_matches(url_matche, save_path = "match_results.rds")
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matche <- c("https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016")
# Appel de la fonction
results <- process_matches(url_matche, save_path = "match_results.rds")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matche <- c("https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs
url_matche <- c("https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016")
# Appel de la fonction
results <- process_matches(url_matche, save_path = "match_results.rds")
# Afficher les résumés
lapply(results, function(match) print(match$Summary))
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs de matchs
url_matches <- c(
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402015",
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402016"
)
# Appel de la fonction
results <- process_matches(url_matches, save_path = "match_results.rds")
# Affichage des résumés sans répétition
cat("\n=== Résumés des matchs ===\n")
for (match in results) {
if (!is.null(match)) {
cat(match$Summary, "\n")
}
}
for (match in results) {
if (!is.null(match)) {
cat(match$Summary, "\n")
}
}
# Fonction finale pour automatiser le traitement d'une liste de matchs
process_matches <- function(url_list, save_path = NULL) {
# Charger les librairies nécessaires
library(httr)
library(stringr)
library(xml2)
library(rvest)
library(dplyr)
# Fonction interne pour extraire les données d'un match
extract_match_summary <- function(match_url) {
# Configurer le user-agent
user_agent <- user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0")
# Requête GET pour récupérer le contenu HTML
response <- GET(match_url, user_agent)
if (response$status_code != 200) return(NULL)
# Chargement et nettoyage du contenu HTML
html <- read_html(content(response, "text"))
clean_html <- str_replace_all(as.character(html), '[\\t\\r\\n\\f]', '')
page <- read_html(clean_html)
# Extraction des informations principales
competition <- page %>% html_node(".direct-headline__header") %>% html_text(trim = TRUE)
home_team <- page %>% html_node(".sb-team.sb-heim .sb-vereinslink") %>% html_text(trim = TRUE)
away_team <- page %>% html_node(".sb-team.sb-gast .sb-vereinslink") %>% html_text(trim = TRUE)
result <- page %>% html_node(".sb-endstand") %>% html_text(trim = TRUE)
spectators <- page %>% html_node(".sb-zusatzinfos strong") %>% html_text(trim = TRUE)
stadium <- page %>% html_node(".sb-zusatzinfos a") %>% html_text(trim = TRUE)
# Résumé narratif
summary <- paste(
"Dans le cadre de la compétition", competition, ", le match opposant",
home_team, "et", away_team, "s'est déroulé à", stadium, "devant", spectators, "spectateurs.",
"Le score final est de", result, "."
)
return(list(
Competition = competition,
HomeTeam = home_team,
AwayTeam = away_team,
Result = result,
Spectators = spectators,
Stadium = stadium,
Summary = summary
))
}
# Traitement de la liste d'URLs
all_matches <- lapply(url_list, function(url) {
tryCatch(extract_match_summary(url), error = function(e) NULL)
})
# Sauvegarde des résultats si un chemin est fourni
if (!is.null(save_path)) {
saveRDS(all_matches, file = save_path)
}
return(all_matches)
}
# Liste des URLs de matchs
url_matche <- c(
"https://www.transfermarkt.fr/spielbericht/index/spielbericht/4402015")
# Appel de la fonction
results <- process_matches(url_matche, save_path = "match_results.rds")
# Affichage résumé
cat("\n=== Résumé des matchs ===\n")
for (match in results) {
if (!is.null(match)) {
cat(match$Summary, "\n")
}
}
---
title: "Techniques de programmation"
---
title: "Techniques de programmation"
---
title: "Techniques de programmation"
---
title: "Techniques de programmation"
## 2 Création d'un résumé à partir des données collèctées
Une fois les données extraites il est possible de créer un résumé naratif du match:
## 2 Création d'un résumé à partir des données collèctées
Une fois les données extraites il est possible de créer un résumé naratif du match:
if (formation_home == formation_away) {
resume = paste(resume, ", tout comme les hommes de", T.away, ", également disposés en", formation_away, ".")
} else {
resume = paste(resume, ", tandis que les hommes de", T.away, "étaient disposés en", formation_away, ".")
}
